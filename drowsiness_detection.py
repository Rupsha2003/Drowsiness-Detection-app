# -*- coding: utf-8 -*-
"""Drowsiness_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o5NuMWwIDTBWLjpAHkHhPaBZTqTwEt45
"""

from google.colab import drive
drive.mount('/content/drive')

# The '-q' flag makes the output less noisy (quiet)
# The '-d' flag specifies the destination directory

!unzip -q "/content/drive/My Drive/dataset/Drowsiness_data.zip" -d "/content/dataset/"

import os
import cv2
import numpy as np

# Set the path to your dataset
DATASET_PATH = "/content/dataset/Drowsiness_data" # <-- IMPORTANT: Update this path
DROWSY_FOLDER = os.path.join(DATASET_PATH, "drowsy")
NON_DROWSY_FOLDER = os.path.join(DATASET_PATH, "notdrowsy")

image_paths = []
labels = []

# Load drowsy images and label them as 1
for img_file in os.listdir(DROWSY_FOLDER):
    image_paths.append(os.path.join(DROWSY_FOLDER, img_file))
    labels.append(1)

# Load non-drowsy images and label them as 0
for img_file in os.listdir(NON_DROWSY_FOLDER):
    image_paths.append(os.path.join(NON_DROWSY_FOLDER, img_file))
    labels.append(0)

print(f"Total images found: {len(image_paths)}")
print(f"Total labels: {len(labels)}")

pip install dlib

import dlib
import os

PREDICTOR_PATH = "shape_predictor_68_face_landmarks.dat"

# Check if the predictor file exists, if not, download it.
if not os.path.exists(PREDICTOR_PATH):
    print(f"Predictor file not found at {PREDICTOR_PATH}. Please run the cell above to download it.")
else:
    detector = dlib.get_frontal_face_detector()
    predictor = dlib.shape_predictor(PREDICTOR_PATH)

    def extract_eye_region(image_path):
        """
        Loads an image, detects the face, and crops out the combined eye region.
        """
        img = cv2.imread(image_path)
        if img is None:
            return None

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        rects = detector(gray, 0)

        if len(rects) == 0:
            return None # No face detected

        # We only use the first detected face
        rect = rects[0]
        shape = predictor(gray, rect)
        shape = np.array([(shape.part(i).x, shape.part(i).y) for i in range(68)])

        # Get coordinates for left and right eyes
        left_eye = shape[36:42]
        right_eye = shape[42:48]

        # Find the bounding box for the combined eye region
        x_min = min(left_eye[:, 0].min(), right_eye[:, 0].min())
        x_max = max(left_eye[:, 0].max(), right_eye[:, 0].max())
        y_min = min(left_eye[:, 1].min(), right_eye[:, 1].min())
        y_max = max(left_eye[:, 1].max(), right_eye[:, 1].max())

        # Add some padding
        x_min = max(0, x_min - 5)
        x_max = min(img.shape[1], x_max + 5)
        y_min = max(0, y_min - 5)
        y_max = min(img.shape[0], y_max + 5)

        eye_region = img[y_min:y_max, x_min:x_max]
        return eye_region



# Download the shape predictor model
!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2
!bunzip2 shape_predictor_68_face_landmarks.dat.bz2

IMG_SIZE = (80, 80)
X = [] # To store image data
y = [] # To store labels

for i, path in enumerate(image_paths):
    eye_image = extract_eye_region(path)
    if eye_image is not None:
        # Resize and convert to grayscale
        eye_image_gray = cv2.cvtColor(eye_image, cv2.COLOR_BGR2GRAY)
        eye_image_resized = cv2.resize(eye_image_gray, IMG_SIZE)

        X.append(eye_image_resized)
        y.append(labels[i])

# Convert lists to NumPy arrays
X = np.array(X)
y = np.array(y)

# Normalize pixel values to be between 0 and 1
X = X / 255.0

# Reshape X to be (num_samples, height, width, channels)
# Grayscale has 1 channel
X = X.reshape(X.shape[0], IMG_SIZE[0], IMG_SIZE[1], 1)

print(f"Dataset shape (X): {X.shape}")
print(f"Labels shape (y): {y.shape}")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from sklearn.model_selection import train_test_split

def build_cnn_model(input_shape):
    model = Sequential()

    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Flatten())

    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))

    # Output layer for binary classification
    model.add(Dense(1, activation='sigmoid'))

    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    model.summary()
    return model

# Define input shape based on our preprocessed images
input_shape = (IMG_SIZE[0], IMG_SIZE[1], 1)
model = build_cnn_model(input_shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from sklearn.model_selection import train_test_split

def build_cnn_model(input_shape):
    model = Sequential()

    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))

    model.add(Flatten())

    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))

    # Output layer for binary classification
    model.add(Dense(1, activation='sigmoid'))

    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    model.summary()
    return model

# Define input shape based on our preprocessed images
input_shape = (IMG_SIZE[0], IMG_SIZE[1], 1)
model = build_cnn_model(input_shape)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"X_train shape: {X_train.shape}")
print(f"X_test shape: {X_test.shape}")

# Train the model
history = model.fit(
    X_train,
    y_train,
    epochs=5,
    batch_size=32,
    validation_data=(X_test, y_test)
)

# Save the trained model for deployment
model.save("drowsiness_cnn_model.h5")

from sklearn.metrics import classification_report, confusion_matrix

# Make predictions on the test set
y_pred_proba = model.predict(X_test)
y_pred = (y_pred_proba > 0.5).astype("int32")

# Print classification report and confusion matrix
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=["Non-Drowsy", "Drowsy"]))

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

from tensorflow.keras.models import load_model

# Load the trained model
model = load_model("drowsiness_cnn_model.h5")

# Initialize dlib's face detector and landmark predictor
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")

cap = cv2.VideoCapture(0)
drowsy_counter = 0
ALARM_THRESHOLD = 20 # Number of consecutive drowsy frames to trigger alarm

while True:
    ret, frame = cap.read()
    if not ret:
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    rects = detector(gray, 0)

    if len(rects) > 0:
        rect = rects[0]
        # (Preprocessing is the same as the function used for training)
        # We find landmarks and crop the eye region
        shape = predictor(gray, rect)
        shape = np.array([(shape.part(i).x, shape.part(i).y) for i in range(68)])

        left_eye = shape[36:42]
        right_eye = shape[42:48]

        x_min = min(left_eye[:, 0].min(), right_eye[:, 0].min())
        x_max = max(left_eye[:, 0].max(), right_eye[:, 0].max())
        y_min = min(left_eye[:, 1].min(), right_eye[:, 1].min())
        y_max = max(left_eye[:, 1].max(), right_eye[:, 1].max())

        eye_region = gray[y_min-5:y_max+5, x_min-5:x_max+5]

        if eye_region.size != 0:
            # Resize and normalize the eye region for the model
            eye_image_resized = cv2.resize(eye_region, IMG_SIZE)
            eye_image_normalized = eye_image_resized / 255.0
            model_input = eye_image_normalized.reshape(1, IMG_SIZE[0], IMG_SIZE[1], 1)

            # Predict
            prediction = model.predict(model_input)[0][0]

            if prediction > 0.5: # Drowsy
                drowsy_counter += 1
                status = "Drowsy"
                if drowsy_counter > ALARM_THRESHOLD:
                    cv2.putText(frame, "DROWSINESS ALERT!", (10, 30),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else: # Not Drowsy
                drowsy_counter = 0
                status = "Alert"

            cv2.putText(frame, f"Status: {status} ({prediction:.2f})", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

    cv2.imshow("Drowsiness Detection", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()